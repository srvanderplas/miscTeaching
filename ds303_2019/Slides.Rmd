---
title: "Visual Diagnostics for Statistical Modeling"
date: "2018-09-16"
output:
  xaringan::moon_reader:
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width = 9, fig.height = 6, dpi = 300, cache = T)

library(tidyverse)
theme_set(theme_bw())
```

class: inverse,middle,center
# Randomness, Models, and Errors

```{r, echo = F}
olympic100m <- read_csv("materials/labs/linear_regression/data100m.csv", col_names = c("year", "time"), col_types = "dd") %>%
  mutate(type = "data")
model <- lm(time ~ year, data = olympic100m)
pred <- tibble(year = seq(1895, 2015, .5)) %>%
  mutate(time = predict(model, newdata = .),
         type = "prediction") %>%
  bind_rows(olympic100m) %>%
  arrange(year) %>%
  spread(key = type, value = time) %>%
  mutate(error = data - prediction)
```

---
class: middle

- Monday: Slides 1-37


- Wednesday: [Slide 38](#wednesday-start)-59

- Friday: [Slide 60](#friday-start) - end

---
class: middle,center
### In the beginning, there was the data...

---

```{r init-olympic, echo = F}
ggplot(olympic100m, aes(x = year, y = time)) + 
  geom_point() + 
  xlim(c(1895, 2015)) + 
  xlab("Year") + ylab("Time (s)") + ggtitle("Winning Olympic men's 100m times")
```
--
and the statistician said "Let there be a model". 

---

```{r init-olympic-lm, echo = F, warning = F}
ggplot(pred, aes(x = year)) + 
  geom_point(aes(y = data)) + 
  geom_line(aes(y = prediction), linetype = "dashed") + 
  xlim(c(1895, 2015)) + 
  xlab("Year") + ylab("Time (s)") + ggtitle("Winning Olympic men's 100m times")
```

And we fit a linear model. 

---

```{r init-olympic-errors, echo = F, warning = F}
ggplot(pred, aes(x = year)) + 
  geom_point(aes(y = data)) + 
  geom_line(aes(y = prediction), linetype = "dashed") + 
  xlim(c(1895, 2015)) + 
  geom_segment(aes(x = year, xend = year, y = data, yend = prediction), color = "red") + 
  xlab("Year") + ylab("Time (s)") + ggtitle("Winning Olympic men's 100m times")
```

The model separated the data into predictions and errors, 

---

```{r init-olympic-known-unknown, echo = F, warning = F}
pred2 <- pred %>%
  select(year, data = data, prediction, error = error) %>%
  filter(!is.na(data)) %>%
  gather(key = "variation", value = "value", -data, -year) %>%
  mutate(variation = factor(variation, c("prediction", "error")),
         endpoint = ifelse(variation == "prediction", min(data), 0))
  
ggplot(pred2, aes(x = year, y = value, xend = year, yend = endpoint)) + 
  geom_point() + 
  geom_segment(aes(color = variation)) + 
  facet_grid(variation~., space = "free_y", scales = "free") +  
  scale_color_manual("Variation", values = c("error" = "red", "prediction" = "blue"), guide = F) + 
  xlim(c(1895, 2015)) + 
  xlab("Year") + 
  scale_y_continuous("Time (s)", breaks = seq(-0.5, 12, 0.5)) + 
  ggtitle("Winning Olympic men's 100m times")
```

or "known" and "unknown" sources of variation. 
---
class: middle,center

The statistician called the "unknown" variation __random error__,    
but s/he did not rest. 
<br/><br/><br/>
--
[Variance Decomposition Derivation](https://en.wikipedia.org/wiki/Variance#Decomposition)


---
## Randomness and Error

Linear regression model form: $$y = w_0 + w_1 x$$

--

This model is __deterministic__ - you will always get the same $y$ value when you have multiple observations at the same $x$

<br/><br/>

--

Probabilistic version: $$y = w_0 + w_1 x + \epsilon$$

$\epsilon$ represents "random error"

A __random variable__ is a variable that can take on many values with different probabilities. $x$, $y$, and $\epsilon$ are random variables. 

---
## Sources of Error

- measurement
- environmental
- human
- modeling

We group all of these into "random error" and model it with $\epsilon$. 

![Calvin and Hobbes on Surveys](calvin_hobbes_messing_with_data.png)

---
## Random Variables

Random variables have a __distribution__ of potential values.

```{r, fig.width = 8, fig.height = 4, echo = F, message = F, warning = F}
x <- rnorm(200)
normaldf <- tibble(x = seq(-4, 4, .01), y = dnorm(x))

p1 <- ggplot() + 
  geom_histogram(aes(x = x, y = ..density..), fill = "grey", color = "black") + 
  geom_line(aes(x = x, y = y), data = normaldf) + 
  ggtitle("Continuous Distribution")

x2 <- rpois(200, lambda = 1)
poisdf <- tibble(x = seq(0, 10, 1), theoretical = dpois(x, 1), 
                 actual = purrr::map_dbl(x, ~sum(x2 == .)/length(x2))) #%>%
  #tidyr::gather(key = "type", value = "prob", -x)


p2 <- ggplot(data = poisdf) + 
  geom_bar(aes(x = x, y = actual), color = "black", fill = "grey", stat = "identity") + 
  geom_point(aes(x = x, y = theoretical)) + 
  scale_x_continuous(breaks = 1:10) + 
  ylab("prob") + 
  ggtitle("Discrete Distribution")

gridExtra::grid.arrange(p1, p2, ncol = 2)
```

---
## Statistical Modeling

We usually assume that errors are

- independent (of other errors)

- identically distributed (all errors come from the same distribution)

- (sometimes) errors come from a specific distribution

--

... that's where the trouble starts...

---
## Statistical Modeling

Most of the trouble in modeling and prediction comes from three places:

- non-independent errors    
e.g. relationships between points within the data set

- non identical errors    
e.g. systematic variation not accounted for by the model

- mismatches between model assumptions and the distribution of the errors

---
class: middle, center, inverse
# Visual Diagnostics for Models


---
## Visual Diagnostics for Models

For some model $$y = f(\vec{x}) + \epsilon$$

- How do we examine our errors for problems?

- How do we determine what model (of several) fits the data best?

---

## Exploratory Data Analysis

Before you start modeling

- Plot $y$ against any explanatory variables $x_1, ..., x_n$

- Plot the distribution of $y$, the distribution of $x_1, ..., x_n$ to look for unexpected features

- Plot the relationship between different $x_i$'s

???

Visualization is an art as well as a science, and requires thinking critically about your data while being open to finding new things.

---

## United Nations Human Development Data


The United Nations maintains a dataset with quality-of-life indicators for most countries in the world. You can explore the data [here](http://hdr.undp.org/en/data). 

There is also a "World Happiness Index" ([link](https://countryeconomy.com/demography/world-happiness-index))

Let's predict happiness based on factors in the UN Quality of Life dataset

```{r, message=F}
library(tidyverse)
# csv url: https://raw.githubusercontent.com/srvanderplas/
#          miscTeaching/master/ds303_2019/2017_Human_Dev_Index.csv

hdi_2017 <- read_csv("https://bit.ly/2mbYdfX")

hdi_2017
```

---
## Exploratory Data Analysis

What variables might be relevant to the Happiness Index on a national scale?

```{r, fig.width = 6, fig.height = 3, message = F, warning = F}
ggplot(hdi_2017) + 
  geom_point(aes(x = GDP, y = Happiness_Index))
```


---
## Exploratory Data Analysis

What variables might be relevant to the Happiness Index on a national scale?

```{r, fig.width = 6, fig.height = 3, message = F, warning = F}
ggplot(hdi_2017) + 
  geom_point(aes(x = GDP, y = Happiness_Index)) + 
  xlim(c(0, 2500))
```

---
## Exploratory Data Analysis

```{r, fig.width = 6, fig.height = 3, message = F, warning = F}
ggplot(hdi_2017) + 
  geom_point(aes(x = GDP, y = Happiness_Index)) + 
  scale_x_log10()
```
$\log_{10}(GDP)$

---
## Exploratory Data Analysis

```{r, fig.width = 6, fig.height = 3, message = F, warning = F}

ggplot(hdi_2017) + 
  geom_point(aes(x = Gross_National_Income, y = Happiness_Index))

```

Might not be linearly related, but definitely related...

---
## Exploratory Data Analysis

```{r, fig.width = 6, fig.height = 3, message = F, warning = F}
ggplot(hdi_2017) + 
  geom_point(aes(x = Life_Exp_Birth, y = Happiness_Index))

```

Again, possible nonlinearity, but definitely related

---
## Exploratory Data Analysis

```{r, fig.width = 6, fig.height = 3, message = F, warning = F}
ggplot(hdi_2017) + 
  geom_point(aes(x = Parlaiment_Pct_Female, y = Happiness_Index))
```

---
## Exploratory Data Analysis

```{r, fig.width = 6, fig.height = 3, message = F, warning = F}
ggplot(hdi_2017) + 
  geom_point(aes(x = Teen_Birth_Rate, y = Happiness_Index))

```
---
## Exploratory Data Analysis

```{r, fig.width = 6, fig.height = 3, message = F, warning = F}
ggplot(hdi_2017) + 
  geom_point(aes(x = Ineq_education, y = Happiness_Index))
```
Inequality in Education(%) : Inequality in distribution of years of schooling based on data from household surveys... [Source](http://hdr.undp.org/en/composite/IHDI#a)

---
## Exploratory Data Analysis

```{r, fig.width = 6, fig.height = 3, message = F, warning = F}
ggplot(hdi_2017) + 
  geom_point(aes(x = Ineq_income, y = Happiness_Index))
```

---
## Exploratory Data Analysis

```{r, fig.width = 6, fig.height = 3, message = F, warning = F}
ggplot(hdi_2017) + 
  geom_point(aes(x = Ineq_Life_Exp, y = Happiness_Index))
```

---
## Exploratory Data Analysis

```{r, eval = F}
model_data <- select(hdi_2017, Country, Happiness_Index, 
                     Ineq_education, Ineq_income, Ineq_Life_Exp, 
                     Teen_Birth_Rate, Life_Exp_Birth, 
                     GDP, Gross_National_Income) %>%
  mutate(log10GDP = log10(GDP)) %>%
  select(-GDP) %>%
  na.omit()

install.packages("GGally")
library(GGally)
ggscatmat(data = model_data[, -c(1:2)]) 
# Scatterplot Matrix - see all of the independent variables and how they relate
# to each other

```


---
## Exploratory Data Analysis

```{r, echo = F, fig.width = 10, fig.height = 10, out.width = "60%", message = F, warning = F}
model_data <- select(hdi_2017, Country, Happiness_Index, 
                     Ineq_education, Ineq_income, Ineq_Life_Exp, 
                     Teen_Birth_Rate, Life_Exp_Birth, 
                     GDP, Gross_National_Income) %>%
  mutate(log10GDP = log10(GDP)) %>%
  select(-GDP) %>%
  na.omit()

GGally::ggscatmat(data = model_data[, -c(1:2)]) 

```

---
## Fit a model

```{r}
bad_model <- lm(Happiness_Index ~ ., data = select(model_data, -Country))
summary(bad_model)
model_data$bad_model_resid <- residuals(bad_model)
model_data$bad_model_predictions <- predict(bad_model, newdata = model_data)
```

---
## Model Diagnostics

```{r, fig.width = 6, fig.height = 3, message = F, warning = F}
n_density <- tibble(x = seq(-3, 3, .01), y = dnorm(x))
ggplot(model_data, aes(x = bad_model_resid)) + 
  geom_histogram(aes(y = ..density..), binwidth = .2)
```

---
## Model Diagnostics

```{r, fig.width = 6, fig.height = 3, message = F, warning = F}
ggplot(model_data, aes(sample = bad_model_resid)) + 
  geom_qq() + 
  geom_qq_line()
```

---
## Model Diagnostics

```{r, fig.width = 6, fig.height = 3, message = F, warning = F}

ggplot(data = model_data, aes(x = Happiness_Index, y = bad_model_predictions)) + 
  geom_point() + geom_abline(slope = 1, intercept = 0)
```

---
## Model Diagnostics

```{r, fig.width = 6, fig.height = 3, message = F, warning = F}
ggplot(data = model_data, aes(x = Happiness_Index, y = bad_model_resid)) + 
  geom_point() + geom_smooth(method = "lm")
```

---
## Model Diagnostics

```{r, fig.width = 6, fig.height = 3, message = F, warning = F}
ggplot(data = model_data, aes(x = cut_number(Happiness_Index, 8), y = bad_model_resid)) + 
  geom_jitter() + 
  geom_boxplot(alpha = .5)
```



---
## Model Diagnostics

```{r, fig.width = 6, fig.height = 3, message = F, warning = F}
model_data$bad_model_resid <- residuals(bad_model)

ggplot(data = model_data, aes(x = Gross_National_Income, y = bad_model_resid)) + 
  geom_point() + geom_smooth(method = "lm")
```



---
name:wednesday-start
## Get set up

```{r}
# Get essential code from monday's class - 
#   - read in data
#   - fit bad model
#   - save bad model predictions/residuals
source("http://bit.ly/ds303-monday")
```

---
## Fit another model
```{r}
meh_model <- lm(Happiness_Index ~ ., 
                data = select(model_data, -Country, 
                              -Gross_National_Income, 
                              -matches("bad_model")))
summary(meh_model)
model_data$meh_model_resid <- resid(meh_model)
```

---
## Model Diagnostics

```{r, fig.width = 6, fig.height = 3, message = F, warning = F}
ggplot(data = model_data, 
       aes(x = Happiness_Index, y = meh_model_resid)) + 
  geom_point() + geom_smooth(method = "lm")
```

---
## Model Comparison

```{r, fig.width = 6, fig.height = 3, message = F, warning = F}
ggplot(data = model_data, 
       aes(x = meh_model_resid, y = bad_model_resid)) + 
  geom_point() + geom_smooth(method = "lm")
```
Removing a significant variable from the model and nothing changes...

---
## Model Diagnostics

```{r, fig.width = 6, fig.height = 3, message = F, warning = F}
ggplot(data = model_data, 
       aes(x = Ineq_education, y = meh_model_resid)) + 
  geom_point() + 
  geom_smooth()
```

---
## Model Diagnostics
```{r, fig.width = 6, fig.height = 3, message = F, warning = F}
ggplot(data = model_data, 
       aes(x = Ineq_income, y = meh_model_resid)) + 
  geom_point() + 
  geom_smooth()
```

---
## Model Diagnostics
```{r, fig.width = 6, fig.height = 3, message = F, warning = F}
ggplot(data = model_data, 
       aes(x = Ineq_Life_Exp, y = meh_model_resid)) + 
  geom_point() + 
  geom_smooth()
```


---
## Model Diagnostics
```{r, fig.width = 6, fig.height = 3, message = F, warning = F}
ggplot(data = model_data, 
       aes(x = Teen_Birth_Rate, y = meh_model_resid)) + 
  geom_point() + 
  geom_smooth()
```


---
## Model Diagnostics
```{r, fig.width = 6, fig.height = 3, message = F, warning = F}
ggplot(data = model_data, 
       aes(x = Life_Exp_Birth, y = meh_model_resid)) + 
  geom_point() + 
  geom_smooth()
```



---
## Model Diagnostics
```{r, fig.width = 6, fig.height = 3, message = F, warning = F}
ggplot(data = model_data, 
       aes(x = log10GDP, y = meh_model_resid)) + 
  geom_point() + 
  geom_smooth()
```

---
## Generalized Linear Model Diagnostics - Leverage

```{r, fig.width = 8, fig.height = 5, out.width = "100%", eval = F}
library(car)
leveragePlots(meh_model, layout = c(2, 3))
```

```{r, fig.width = 8, fig.height = 5, out.width = "100%", echo = F}
suppressMessages(library(car))
leveragePlots(meh_model, layout = c(2, 3))
```
High-Leverage points have a large potential to affect the results of an analysis. They are not always visible from residual plots. 

---
## Generalized Linear Model Diagnostics - Leverage
<br/><br/>
$$\text{leverage at }x_i = h_{ii} = \frac{1}{n} + \frac{(x_i - \bar{x})^2}{\sum_i(x_i - \bar{x})^2}$$

Leverage is mostly important in functional regression models; it has relatively small effects in ensemble models such as random forests.

---
## Generalized Linear Model Diagnostics - Influence

```{r, fig.width = 8, fig.height = 4}
cutoff <- 4/((nrow(model_data) - length(meh_model$coefficients) - 2))
plot(meh_model, which = 4, cook.levels = cutoff)
```

Cook's distance identifies points which are too influential.

---
## Generalized Linear Model Diagnostics - Influence

```{r, warning = F, message = F, fig.width = 8, fig.height = 4}
res <- influencePlot(meh_model, id.method = "identify", main = "Influence Plot", 
                     sub = "Circle size is proportial to Cook's Distance")
```

---
## Generalized Linear Model Diagnostics - Influence

Extra reading: 

- [Studentized residuals](https://en.wikipedia.org/wiki/Studentized_residual) - residuals from leave-one-out cross-validation     
(leave out that point, fit the model, predict for the left-out point, calculate the residual)

- [Hat-values](https://en.wikipedia.org/wiki/Projection_matrix) - influence each response value has on the fitted value

- [Cook's distance](https://en.wikipedia.org/wiki/Cook%27s_distance): the sum of all the changes in the regression model when observation $i$ is removed $$D_i = \frac{\sum_{j=1}^n (\hat{y}_j - \hat{y}_{j(i)})^2}{ps^2}$$ where p is the number of parameters and $s^2$ is the mean squared error of the regression model

---
## Generalized Linear Model Diagnostics - Influence

```{r}
# Look at high influence or high leverage points
model_data[c(23, 34, 47, 72, 97, 106, 130, 137), 
           c("Country", "Happiness_Index", "meh_model_resid")]
```
(Comoros is an island nation off of the coast of eastern Africa. )



---
## Model Diagnostics

Residual-based diagnostics work for pretty much any type of model that generates predictions.

```{r, eval = F}
library(randomForest)
rf_model <- randomForest(Happiness_Index ~ ., 
                         data = select(model_data, -Country))
print(rf_model)
model_data$rf_predict <- predict(rf_model)
model_data$rf_resid <- model_data$Happiness_Index - 
  model_data$rf_predict
```

```{r, eval = T, include = F}
library(randomForest)
rf_model <- randomForest(Happiness_Index ~ ., 
                         data = select(model_data, -Country))
print(rf_model)
model_data$rf_predict <- predict(rf_model)
model_data$rf_resid <- model_data$Happiness_Index - 
  model_data$rf_predict
```

You'll talk about random forests later in the semester. They're not a linear model, so they work a bit differently.

---
## Model Diagnostics

```{r, fig.width = 6, fig.height = 3, message = F, warning = F}
ggplot(data = model_data, 
       aes(x = Happiness_Index, y = rf_predict)) + 
  geom_point() + 
  geom_abline(slope = 1, intercept = 0)
```


---
## Model Diagnostics

```{r, fig.width = 6, fig.height = 3, message = F, warning = F}
ggplot(data = model_data, 
       aes(x = Happiness_Index, y = rf_resid)) + 
  geom_point() + 
  geom_smooth(method = "lm")
```

---
## Model Diagnostics

```{r, fig.width = 6, fig.height = 3, message = F, warning = F}
ggplot(data = model_data, aes(x = rf_resid)) + 
  geom_histogram()
```


---
## Model Comparison

```{r, fig.width = 6, fig.height = 3, message = F, warning = F}
ggplot(data = model_data, 
       aes(x = meh_model_resid, y = rf_resid)) + 
  geom_point() + 
  geom_abline(slope = 1, intercept = 0) + 
  coord_fixed(ratio = 1) + 
  geom_smooth(se = F)
```

---
## Your Turn

- Work in groups of 3-4
- Pick 1 dataset:
  - Education-related variables (http://bit.ly/ds303_edu)
  - GDP-related variables (http://bit.ly/ds303_gdp)
  - other Indexes as variables (http://bit.ly/ds303_idx)
  - Medical and Poverty-related variables (http://bit.ly/ds303_med)

- Each dataset has predicted values from 3 models: 
  - a knn model
  - a linear model
  - a random forest

- Compare the models, identify areas where each model doesn't fit, and (if you have time) find other variables (columns after Country in the csv) which might be important to include


---
class:middle,inverse,center
name: friday-start
## Visualizations for Cross-Validation 

---
## Tidy models

- A unified framework for modeling in R

- Goal is to have the same (tidy) output for common models to facilitate comparisons

- `parsnip`: tidy interface for models,

- `broom`: tidy format for model analysis objects, 

- `yardstick`: tidy measures of model performance

- `rsample`: tidy ways to resample data (cross-validation, etc.)

```{r, eval = F}
library(tidyverse)
install.packages(c("parsnip", "broom", "yardstick", 
                   "rsample", "tidymodels", "AmesHousing"))
```

---
## The `parsnip` package

```{r, message = F, warning = F}
library(tidyverse)
library(tidymodels)
library(AmesHousing)
ames <- make_ames()
set.seed(4595)
# Split data into training and test set
data_split <- initial_split(ames, strata = "Sale_Price", p = 0.9)
ames_train <- training(data_split)
ames_test  <- testing(data_split)
```

---
## Parsnip

```{r}
rf_model <- rand_forest(mode = "regression") %>% 
  set_engine("ranger") # set_engine specifies 
                       # how the model is fit
linear_model <- linear_reg() %>% 
  set_engine("lm")

models <- tibble::tibble(
  model_name = c("random_forest", "linear_regression"), 
  model_fcn = list(rf_model, linear_model)) %>%
  dplyr::mutate(
    # fit using the training set
    res = purrr::map(
      model_fcn, 
      ~fit(., formula = log10(Sale_Price) ~ 
             Longitude + Latitude + 
             Lot_Area + Neighborhood + 
             Year_Sold, data = ames_train)),
    # predict based on the test set
    pred = purrr::map(res, predict, 
                      new_data = ames_test)
  )
```

---
## Parsnip
```{r}
models$res[[1]]
```

---
## Parsnip
```{r}
models$res[[2]]
```

---
## Parsnip - Model Comparisons

```{r, fig.width = 4, fig.height = 4, out.width = "75%"}
ames_test_preds <- models %>%
  # Get predictions and model names
  select(model_name, pred) %>% 
  # Make a long, skinny data frame
  unnest() %>% 
  # rename variables
  rename(pred = .pred) %>% 
  # For each model, 
  group_by(model_name) %>% 
  # number the rows 1:n(), where n() = 731
  mutate(row = 1:n()) %>%  
  # Put each model in a different column
  spread(key = model_name, value = pred) %>% 
  # Add in the actual test set data
  bind_cols(ames_test) %>% 
  # Go back to a long-form dataset where predictions are in one column
  gather(key = "model_name", value = "pred", 
         random_forest:linear_regression)
```

---
## Model Comparisons

```{r, fig.width = 8, fig.height = 4, out.width = "100%"}
ggplot(aes(x = log10(Sale_Price), y = pred), 
       data = ames_test_preds) + 
  geom_point() + facet_wrap(~model_name) + 
  coord_fixed() + 
  ggtitle("Test Set Predictions")
```

```{r, include = F, eval = F}
bunch_of_models <- tibble(variable = names(select(ames_train, -Sale_Price)),
       formula = paste("log10(Sale_Price) ~", variable) %>% purrr::map(as.formula)) %>%
  mutate(model = purrr::map(formula, ~lm(., data = ames_train)),
         msum = purrr::map(model, summary),
         rsq = purrr::map_dbl(msum, "adj.r.squared"),
         df = purrr::map_int(model, "rank")) %>%
  arrange(desc(rsq))
```

---

## Cross-Validation

```{r}
ames_train_1var <- select(ames_train, Sale_Price, Gr_Liv_Area)
ames_cv <- vfold_cv(ames_train_1var, v = 30, strata = "Sale_Price", breaks = 8)
ames_cv[1,]
ames_cv$splits[[1]]
```

---
## Cross-Validation
```{r}
analysis(ames_cv$splits[[1]])
assessment(ames_cv$splits[[1]])
```

---

## Cross-Validation

```{r}
# Create our model fitting function
ames_lm <- function(cv) {
  lm(formula = log10(Sale_Price) ~ Gr_Liv_Area,
     data = as.data.frame(cv))
}

ames_cv_lm <- ames_cv %>% 
  # map takes each set and applies a function
  mutate(model = purrr::map(splits, ames_lm)) %>%
  # get out the coefficients
  mutate(coefs = purrr::map(model, "coefficients"),
         slope = purrr::map_dbl(coefs, "Gr_Liv_Area"),
         intercept = purrr::map_dbl(coefs, "(Intercept)"))
```

---
## Cross-Validation - Parameter Estimate Error

```{r, fig.width = 4, fig.height = 4, out.width = "50%", message = F}
ggplot(data = ames_cv_lm) + 
  geom_histogram(aes(x = slope)) + 
  ggtitle("Cross-Validated Slope Values")
```

---
## Cross-Validation

```{r}
ames_loess <- function(cv) {
  loess(Sale_Price ~ Gr_Liv_Area, 
        data = analysis(cv))
}

# Make a table of possible predictive values
output_range <- tibble(
  Gr_Liv_Area = min(ames$Gr_Liv_Area):max(ames$Gr_Liv_Area)
) 

# Get regression lines and assessment set predictions
ames_cv_loess <- ames_cv %>% 
  mutate(
    model = purrr::map(splits, ames_loess),
    pred_line = purrr::map(model, ~bind_cols(
      output_range, 
      pred = predict(., newdata = output_range))),
    pred_assessment = purrr::map2(
      model, splits, ~bind_cols(
        assessment(.y), 
        pred = predict(.x, newdata = assessment(.y))))
  )
```

---
## Cross-Validation - Model Variability

```{r, warning = F, fig.width = 8, fig.height = 4, out.width = "100%"}
select(ames_cv_loess, id, pred_line) %>% unnest() %>%
  ggplot() + 
  geom_point(aes(x = Gr_Liv_Area, y = Sale_Price), 
             data = ames_train_1var, color = "red", alpha = .2) + 
  geom_line(aes(x = Gr_Liv_Area, y =  pred, group = id), alpha = .1) + 
  scale_y_log10(breaks = c(50000, 100000, 150000, 300000, 500000))
```
